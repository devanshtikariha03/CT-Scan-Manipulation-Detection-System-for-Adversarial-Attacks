{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom google.colab import drive\n\n# Mount Google Drive\ndrive.mount('/content/drive', force_remount=True)\n\ndef load_ct_image(image_path):\n    \"\"\"Load a CT scan image from the specified path.\"\"\"\n    ct_image = Image.open('/content/drive/MyDrive/ID_0062_AGE_0067_CONTRAST_0_CT.jpg')\n    ct_image_cv = cv2.cvtColor(np.array(ct_image), cv2.COLOR_RGB2BGR)\n    return ct_image, ct_image_cv\n\ndef save_manipulated_image(manipulated_image, output_path):\n    \"\"\"Save the manipulated CT scan image to the specified path.\"\"\"\n    manipulated_ct = Image.fromarray(cv2.cvtColor(manipulated_image, cv2.COLOR_BGR2RGB))\n    manipulated_ct.save(output_path)\n    print(f\"Manipulated CT image saved to: {output_path}\")\n\ndef apply_gaussian_blur(ct_image_cv, roi_x, roi_y, roi_width, roi_height, kernel_size=(5, 5)):\n    \"\"\"Apply Gaussian blur to the specified ROI of the CT scan image.\"\"\"\n    roi = ct_image_cv[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n    blurred_roi = cv2.GaussianBlur(roi, kernel_size, 0)\n    ct_image_cv[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width] = blurred_roi\n    return ct_image_cv\n\ndef apply_contrast_adjustment(ct_image_cv, roi_x, roi_y, roi_width, roi_height, alpha=1.2, beta=20):\n    \"\"\"Adjust the contrast of the specified ROI of the CT scan image.\"\"\"\n    roi = ct_image_cv[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n    adjusted_roi = cv2.convertScaleAbs(roi, alpha=alpha, beta=beta)\n    ct_image_cv[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width] = adjusted_roi\n    return ct_image_cv\n\ndef apply_edge_enhancement(ct_image_cv, roi_x, roi_y, roi_width, roi_height, kernel_size=(3, 3)):\n    \"\"\"Apply edge enhancement to the specified ROI of the CT scan image.\"\"\"\n    roi = ct_image_cv[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n    edge_kernel = np.array([[-1, -1, -1],\n                           [-1, 8, -1],\n                           [-1, -1, -1]])\n    enhanced_roi = cv2.filter2D(roi, -1, edge_kernel)\n    ct_image_cv[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width] = enhanced_roi\n    return ct_image_cv\n\ndef main():\n    # Load the target CT scan image\n    target_ct_path = '/content/drive/MyDrive/ID_0061_AGE_0074_CONTRAST_0_CT.jpg'\n    target_ct, target_ct_cv = load_ct_image(target_ct_path)\n\n    # Define the region of interest (ROI) for manipulation\n    roi_x, roi_y, roi_width, roi_height = 100, 200, 300, 400\n\n    # Apply Gaussian blur to the ROI\n    manipulated_ct_cv = apply_gaussian_blur(target_ct_cv, roi_x, roi_y, roi_width, roi_height)\n\n    # Apply contrast adjustment to the ROI\n    manipulated_ct_cv = apply_contrast_adjustment(manipulated_ct_cv, roi_x, roi_y, roi_width, roi_height)\n\n    # Apply edge enhancement to the ROI\n    manipulated_ct_cv = apply_edge_enhancement(manipulated_ct_cv, roi_x, roi_y, roi_width, roi_height)\n\n    # Save the manipulated CT scan image\n    output_path = \"/content/drive/MyDrive/manipulated_ct_2.png\"\n    save_manipulated_image(manipulated_ct_cv, output_path)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom google.colab import drive\nimport tensorflow as tf\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import accuracy_score, f1_score\nimport tifffile\nfrom scipy.spatial.distance import cosine\nimport skimage.feature\nfrom skimage.feature import greycoprops, graycomatrix\n\n# Mount Google Drive\ndrive.mount('/content/drive', force_remount=True)\n\ndef load_ct_image(image_path):\n    \"\"\"Load a CT scan image from the specified path.\"\"\"\n    try:\n        if image_path.endswith('.tif') or image_path.endswith('.tiff'):\n            ct_image = tifffile.imread(image_path)\n            if ct_image.dtype == np.float64:\n                ct_image = ct_image.astype(np.float32)\n            ct_image = cv2.resize(ct_image, (224, 224))\n            ct_image = cv2.cvtColor(ct_image, cv2.COLOR_GRAY2RGB)\n        else:\n            ct_image = cv2.imread(image_path)\n            ct_image = cv2.resize(ct_image, (224, 224))\n        return ct_image\n    except Exception as e:\n        print(f\"Error loading image: {image_path} - {e}\")\n        return None\n\ndef extract_features(image, model):\n    \"\"\"Extract features from the CT scan image using the pre-trained model.\"\"\"\n    image = cv2.resize(image, (224, 224))\n    image = np.expand_dims(image, axis=0)\n    image = preprocess_input(image)\n    features = model.predict(image)\n    return features.flatten()\n\ndef extract_combined_features(image, model):\n    \"\"\"Extract a combination of features from the CT scan image.\"\"\"\n    image = cv2.resize(image, (224, 224))\n    image = np.expand_dims(image, axis=0)\n    image = preprocess_input(image)\n    vgg16_features = model.predict(image).flatten()\n\n    # Extract histogram features\n    hist, _ = np.histogram(image.squeeze(), bins=32, range=(0, 255))\n    hist_features = hist / np.sum(hist)\n\n    # Extract texture features\n    # Convert the image to grayscale before computing GLCM\n    gray_image = cv2.cvtColor(image.squeeze(), cv2.COLOR_RGB2GRAY)\n    glcm = graycomatrix(gray_image.astype(np.uint8), distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256)\n    contrast = skimage.feature.graycoprops(glcm, 'contrast')[0, 0]  # Updated\n    dissimilarity = skimage.feature.graycoprops(glcm, 'dissimilarity')[0, 0]  # Updated\n    homogeneity = skimage.feature.graycoprops(glcm, 'homogeneity')[0, 0]  # Updated\n    energy = skimage.feature.graycoprops(glcm, 'energy')[0, 0]  # Updated\n    correlation = skimage.feature.graycoprops(glcm, 'correlation')[0, 0]  # Updated\n    texture_features = [contrast, dissimilarity, homogeneity, energy, correlation]\n\n    return np.concatenate([vgg16_features, hist_features, texture_features])\n\ndef find_most_similar_original(manipulated_image, original_paths):\n    \"\"\"Find the original image that is most similar to the manipulated image.\"\"\"\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n    model = Sequential()\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))\n\n    manipulated_feature = extract_combined_features(manipulated_image, model)\n\n    min_distance = float('inf')\n    most_similar_path = None\n\n    for path in original_paths:\n        original_image = load_ct_image(path)\n        original_feature = extract_combined_features(original_image, model)\n        distance = np.linalg.norm(manipulated_feature - original_feature)\n        if distance < min_distance:\n            min_distance = distance\n            most_similar_path = path\n\n    return most_similar_path\n\n# Test the function with the provided potential_original_paths\npotential_original_paths = [\n\n    \"/content/drive/MyDrive/ID_0000_AGE_0060_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0001_AGE_0069_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0002_AGE_0074_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0003_AGE_0075_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0004_AGE_0056_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0005_AGE_0048_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0006_AGE_0075_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0007_AGE_0061_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0008_AGE_0051_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0009_AGE_0048_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0010_AGE_0060_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0011_AGE_0061_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0012_AGE_0061_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0013_AGE_0060_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0014_AGE_0071_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0015_AGE_0061_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0016_AGE_0063_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0017_AGE_0060_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0018_AGE_0074_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0019_AGE_0070_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0020_AGE_0066_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0021_AGE_0067_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0022_AGE_0074_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0023_AGE_0061_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0024_AGE_0060_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0025_AGE_0074_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0026_AGE_0070_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0027_AGE_0064_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0028_AGE_0074_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0029_AGE_0078_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0030_AGE_0076_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0031_AGE_0039_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0032_AGE_0061_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0033_AGE_0071_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0034_AGE_0061_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0035_AGE_0059_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0036_AGE_0074_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0037_AGE_0074_CONTRAST_1_CT.tif\",\n    \"/content/drive/MyDrive/ID_0062_AGE_0067_CONTRAST_0_CT.tif\"\n]\n\n# Assuming you have a manipulated image, e.g., /content/drive/MyDrive/manipulated_image.tif\nmanipulated_image = load_ct_image(\"/content/drive/MyDrive/manipulated_ct_2.tiff\")\nmost_similar_original = find_most_similar_original(manipulated_image, potential_original_paths)\nprint(f\"The most similar original image is: {most_similar_original}\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}